{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\Projects\\Visual Studio Code\\LM\\.venv\\lib\\site-packages\\transformers\\utils\\hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from src.tokenizers.services.available_tokenizers import available_tokenizers\n",
    "from src.common.models.dataloader_type import DataloaderType\n",
    "import torch\n",
    "from src.nn.services.decoding_strat import GreedyDAGStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = available_tokenizers['helsinki_en_zh']()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.nn.architectures.dag_encoder_decoder import EncoderDecoderDAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"checkpoints/wmt19_en_zh_dag_dropout_0.12/model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = info.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = checkpoint['model_state_dict']\n",
    "kwargs = checkpoint['model_kwargs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EncoderDecoderDAG(\n",
    "    **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderDecoderDAG(\n",
       "  (embedding): StableEmbedding(\n",
       "    (embedding): Embedding(65003, 384)\n",
       "  )\n",
       "  (pos_embedding_enc): StableEmbedding(\n",
       "    (embedding): Embedding(52, 384)\n",
       "  )\n",
       "  (pos_embedding_dec): StableEmbedding(\n",
       "    (embedding): Embedding(208, 384)\n",
       "  )\n",
       "  (enc_layers): ModuleList(\n",
       "    (0-2): 3 x TransformerBlock(\n",
       "      (attn): TransformerAttention(\n",
       "        (attn_proj): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.12, inplace=False)\n",
       "        (out_dropout): Dropout(p=0.12, inplace=False)\n",
       "      )\n",
       "      (ffn): Linear(in_features=384, out_features=1152, bias=True)\n",
       "      (ffn2): Linear(in_features=1152, out_features=384, bias=True)\n",
       "      (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ffn_activation): GELU(approximate='none')\n",
       "      (ffn_dropout): Dropout(p=0.12, inplace=False)\n",
       "      (ffn2_dropout): Dropout(p=0.12, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (dec_layers): ModuleList(\n",
       "    (0): TransformerBlock(\n",
       "      (attn): TransformerAttention(\n",
       "        (attn_proj): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.12, inplace=False)\n",
       "        (out_dropout): Dropout(p=0.12, inplace=False)\n",
       "      )\n",
       "      (ffn): Linear(in_features=384, out_features=1152, bias=True)\n",
       "      (ffn2): Linear(in_features=1152, out_features=384, bias=True)\n",
       "      (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ffn_activation): GELU(approximate='none')\n",
       "      (ffn_dropout): Dropout(p=0.12, inplace=False)\n",
       "      (ffn2_dropout): Dropout(p=0.12, inplace=False)\n",
       "    )\n",
       "    (1): XBlock(\n",
       "      (attn): XAttention(\n",
       "        (q_attn_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (kv_attn_proj): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): Linear(in_features=384, out_features=1536, bias=True)\n",
       "      (ffn2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "      (norm1q): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm1kv): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ffn_activation): GELU(approximate='none')\n",
       "      (ffn_dropout): Dropout(p=0.12, inplace=False)\n",
       "      (ffn2_dropout): Dropout(p=0.12, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (attn): TransformerAttention(\n",
       "        (attn_proj): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.12, inplace=False)\n",
       "        (out_dropout): Dropout(p=0.12, inplace=False)\n",
       "      )\n",
       "      (ffn): Linear(in_features=384, out_features=1152, bias=True)\n",
       "      (ffn2): Linear(in_features=1152, out_features=384, bias=True)\n",
       "      (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ffn_activation): GELU(approximate='none')\n",
       "      (ffn_dropout): Dropout(p=0.12, inplace=False)\n",
       "      (ffn2_dropout): Dropout(p=0.12, inplace=False)\n",
       "    )\n",
       "    (3): XBlock(\n",
       "      (attn): XAttention(\n",
       "        (q_attn_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (kv_attn_proj): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): Linear(in_features=384, out_features=1536, bias=True)\n",
       "      (ffn2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "      (norm1q): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm1kv): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ffn_activation): GELU(approximate='none')\n",
       "      (ffn_dropout): Dropout(p=0.12, inplace=False)\n",
       "      (ffn2_dropout): Dropout(p=0.12, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (attn): TransformerAttention(\n",
       "        (attn_proj): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.12, inplace=False)\n",
       "        (out_dropout): Dropout(p=0.12, inplace=False)\n",
       "      )\n",
       "      (ffn): Linear(in_features=384, out_features=1152, bias=True)\n",
       "      (ffn2): Linear(in_features=1152, out_features=384, bias=True)\n",
       "      (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ffn_activation): GELU(approximate='none')\n",
       "      (ffn_dropout): Dropout(p=0.12, inplace=False)\n",
       "      (ffn2_dropout): Dropout(p=0.12, inplace=False)\n",
       "    )\n",
       "    (5): XBlock(\n",
       "      (attn): XAttention(\n",
       "        (q_attn_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (kv_attn_proj): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): Linear(in_features=384, out_features=1536, bias=True)\n",
       "      (ffn2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "      (norm1q): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm1kv): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ffn_activation): GELU(approximate='none')\n",
       "      (ffn_dropout): Dropout(p=0.12, inplace=False)\n",
       "      (ffn2_dropout): Dropout(p=0.12, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.12, inplace=False)\n",
       "  (output_dag): OutputDAG(\n",
       "    (attn): Linear(in_features=384, out_features=768, bias=True)\n",
       "    (gate): Linear(in_features=384, out_features=6, bias=True)\n",
       "    (lm_head): Linear(in_features=384, out_features=65003, bias=True)\n",
       "    (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unk> 福州是港口城市</s> </s>\n"
     ]
    }
   ],
   "source": [
    "sample = input(\"Enter a sample: \")\n",
    "encoded = tokenizer.encode(sample)\n",
    "bos_idx = info.bos_idx\n",
    "eos_idx = info.eos_idx\n",
    "encoded = [bos_idx] + encoded + [eos_idx]\n",
    "encoded = torch.tensor(encoded).unsqueeze(0)\n",
    "strat = GreedyDAGStrategy(info, device)\n",
    "coeff = 4\n",
    "inferenced = model.naive_inference(encoder_input=encoded, strat=strat, coefficient=coeff)\n",
    "print(tokenizer.decode(inferenced[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
